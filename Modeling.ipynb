{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5ba9248",
   "metadata": {},
   "source": [
    "# Final Project - Modeling\n",
    "##### Name: Shane Staret  \n",
    "##### Class: CSCI 349 - Intro to Data Mining   \n",
    "##### Semester: 2021SP   \n",
    "##### Instructor: Brian King"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d539f2",
   "metadata": {},
   "source": [
    "### **Accomplishments, Challenges, & What to Expect Moving Forward**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2de6002",
   "metadata": {},
   "source": [
    "Well, I was able to find a model that is a pretty good fit! It was not the model I was expecting, but I'm happy that I was able to find a model that had pretty accurate and precise predictions. The most challenging part of the modeling process (by far) was determining the different hyperparameters that must be used within the Keras NN. I tried different activation functions, different epochs, different NN structures (e.g. with hidden layers, without hidden layers, multiple layers with different activation functions, etc)...and unfortunately I was never able to get a Keras NN model that worked as well as I would have hoped.  \n",
    "  \n",
    "Moving forward, everything from this notebook along with the Data Prep/EDA notebook needs to be tied together to form a cohesive narrative about the problem I have addressed and how I have solved it. A deeper dive into the interpretation of the results and the ramification of them will also be explored within the final report."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1308da80",
   "metadata": {},
   "source": [
    "### **Data Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e819247a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shanestaret/opt/anaconda3/envs/csci349/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/shanestaret/opt/anaconda3/envs/csci349/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/shanestaret/opt/anaconda3/envs/csci349/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/shanestaret/opt/anaconda3/envs/csci349/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/shanestaret/opt/anaconda3/envs/csci349/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/shanestaret/opt/anaconda3/envs/csci349/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Users/shanestaret/opt/anaconda3/envs/csci349/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/shanestaret/opt/anaconda3/envs/csci349/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/shanestaret/opt/anaconda3/envs/csci349/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/shanestaret/opt/anaconda3/envs/csci349/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/shanestaret/opt/anaconda3/envs/csci349/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/shanestaret/opt/anaconda3/envs/csci349/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1044 entries, 0 to 1043\n",
      "Data columns (total 34 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   school      1044 non-null   float32\n",
      " 1   sex         1044 non-null   float32\n",
      " 2   age         1044 non-null   float32\n",
      " 3   address     1044 non-null   float32\n",
      " 4   famsize     1044 non-null   float32\n",
      " 5   Pstatus     1044 non-null   float32\n",
      " 6   Medu        1044 non-null   float32\n",
      " 7   Fedu        1044 non-null   float32\n",
      " 8   Mjob        1044 non-null   float32\n",
      " 9   Fjob        1044 non-null   float32\n",
      " 10  reason      1044 non-null   float32\n",
      " 11  guardian    1044 non-null   float32\n",
      " 12  traveltime  1044 non-null   float32\n",
      " 13  studytime   1044 non-null   float32\n",
      " 14  failures    1044 non-null   float32\n",
      " 15  schoolsup   1044 non-null   float32\n",
      " 16  famsup      1044 non-null   float32\n",
      " 17  paid        1044 non-null   float32\n",
      " 18  activities  1044 non-null   float32\n",
      " 19  nursery     1044 non-null   float32\n",
      " 20  higher      1044 non-null   float32\n",
      " 21  internet    1044 non-null   float32\n",
      " 22  romantic    1044 non-null   float32\n",
      " 23  famrel      1044 non-null   float32\n",
      " 24  freetime    1044 non-null   float32\n",
      " 25  goout       1044 non-null   float32\n",
      " 26  Dalc        1044 non-null   float32\n",
      " 27  Walc        1044 non-null   float32\n",
      " 28  health      1044 non-null   float32\n",
      " 29  absences    1044 non-null   float32\n",
      " 30  G1          1044 non-null   uint8  \n",
      " 31  G2          1044 non-null   uint8  \n",
      " 32  G3          1044 non-null   uint8  \n",
      " 33  course      1044 non-null   float32\n",
      "dtypes: float32(31), uint8(3)\n",
      "memory usage: 129.6 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1044 entries, 0 to 1043\n",
      "Data columns (total 32 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   school      1044 non-null   float32\n",
      " 1   sex         1044 non-null   float32\n",
      " 2   age         1044 non-null   float32\n",
      " 3   address     1044 non-null   float32\n",
      " 4   famsize     1044 non-null   float32\n",
      " 5   Pstatus     1044 non-null   float32\n",
      " 6   Medu        1044 non-null   float32\n",
      " 7   Fedu        1044 non-null   float32\n",
      " 8   Mjob        1044 non-null   float32\n",
      " 9   Fjob        1044 non-null   float32\n",
      " 10  reason      1044 non-null   float32\n",
      " 11  guardian    1044 non-null   float32\n",
      " 12  traveltime  1044 non-null   float32\n",
      " 13  studytime   1044 non-null   float32\n",
      " 14  failures    1044 non-null   float32\n",
      " 15  schoolsup   1044 non-null   float32\n",
      " 16  famsup      1044 non-null   float32\n",
      " 17  paid        1044 non-null   float32\n",
      " 18  activities  1044 non-null   float32\n",
      " 19  nursery     1044 non-null   float32\n",
      " 20  higher      1044 non-null   float32\n",
      " 21  internet    1044 non-null   float32\n",
      " 22  romantic    1044 non-null   float32\n",
      " 23  famrel      1044 non-null   float32\n",
      " 24  freetime    1044 non-null   float32\n",
      " 25  goout       1044 non-null   float32\n",
      " 26  Dalc        1044 non-null   float32\n",
      " 27  Walc        1044 non-null   float32\n",
      " 28  health      1044 non-null   float32\n",
      " 29  absences    1044 non-null   float32\n",
      " 30  G3          1044 non-null   uint8  \n",
      " 31  course      1044 non-null   float32\n",
      "dtypes: float32(31), uint8(1)\n",
      "memory usage: 127.6 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ALL DATA PREPROCESSING\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.utils import shuffle\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Input, Model, Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "# reading in the dataset for the math course\n",
    "df_mat = pd.read_csv('data/student-mat.csv', delimiter=';')\n",
    "\n",
    "# reading in the dataset for the Portuguese course\n",
    "df_por = pd.read_csv('data/student-por.csv', delimiter=';')\n",
    "\n",
    "# reassigning dtype for each attribute\n",
    "df_mat['school'] = pd.Categorical(df_mat['school'])\n",
    "df_por['school'] = pd.Categorical(df_por['school'])\n",
    "\n",
    "df_mat['sex'] = pd.Categorical(df_mat['sex'])\n",
    "df_por['sex'] = pd.Categorical(df_por['sex'])\n",
    "\n",
    "df_mat['age'] = pd.to_numeric(df_mat['age'], downcast='unsigned')\n",
    "df_por['age'] = pd.to_numeric(df_por['age'], downcast='unsigned')\n",
    "\n",
    "df_mat['address'] = pd.Categorical(df_mat['address'])\n",
    "df_por['address'] = pd.Categorical(df_por['address'])\n",
    "\n",
    "df_mat['famsize'] = pd.Categorical(df_mat['famsize'])\n",
    "df_por['famsize'] = pd.Categorical(df_por['famsize'])\n",
    "\n",
    "df_mat['Pstatus'] = pd.Categorical(df_mat['Pstatus'])\n",
    "df_por['Pstatus'] = pd.Categorical(df_por['Pstatus'])\n",
    "\n",
    "df_mat['Medu'] = pd.Categorical(df_mat['Medu']).as_ordered()\n",
    "df_por['Medu'] = pd.Categorical(df_por['Medu']).as_ordered()\n",
    "\n",
    "df_mat['Fedu'] = pd.Categorical(df_mat['Fedu']).as_ordered()\n",
    "df_por['Fedu'] = pd.Categorical(df_por['Fedu']).as_ordered()\n",
    "\n",
    "df_mat['Mjob'] = pd.Categorical(df_mat['Mjob'])\n",
    "df_por['Mjob'] = pd.Categorical(df_por['Mjob'])\n",
    "\n",
    "df_mat['Fjob'] = pd.Categorical(df_mat['Fjob'])\n",
    "df_por['Fjob'] = pd.Categorical(df_por['Fjob'])\n",
    "\n",
    "df_mat['reason'] = pd.Categorical(df_mat['reason'])\n",
    "df_por['reason'] = pd.Categorical(df_por['reason'])\n",
    "\n",
    "df_mat['guardian'] = pd.Categorical(df_mat['guardian'])\n",
    "df_por['guardian'] = pd.Categorical(df_por['guardian'])\n",
    "\n",
    "df_mat['traveltime'] = pd.Categorical(df_mat['traveltime']).as_ordered()\n",
    "df_por['traveltime'] = pd.Categorical(df_por['traveltime']).as_ordered()\n",
    "\n",
    "df_mat['studytime'] = pd.Categorical(df_mat['studytime']).as_ordered()\n",
    "df_por['studytime'] = pd.Categorical(df_por['studytime']).as_ordered()\n",
    "\n",
    "df_mat['failures'] = pd.Categorical(df_mat['failures']).as_ordered()\n",
    "df_por['failures'] = pd.Categorical(df_por['failures']).as_ordered()\n",
    "\n",
    "df_mat['schoolsup'] = pd.Categorical(df_mat['schoolsup'])\n",
    "df_por['schoolsup'] = pd.Categorical(df_por['schoolsup'])\n",
    "\n",
    "df_mat['famsup'] = pd.Categorical(df_mat['famsup'])\n",
    "df_por['famsup'] = pd.Categorical(df_por['famsup'])\n",
    "\n",
    "df_mat['paid'] = pd.Categorical(df_mat['paid'])\n",
    "df_por['paid'] = pd.Categorical(df_por['paid'])\n",
    "\n",
    "df_mat['activities'] = pd.Categorical(df_mat['activities'])\n",
    "df_por['activities'] = pd.Categorical(df_por['activities'])\n",
    "\n",
    "df_mat['nursery'] = pd.Categorical(df_mat['nursery'])\n",
    "df_por['nursery'] = pd.Categorical(df_por['nursery'])\n",
    "\n",
    "df_mat['higher'] = pd.Categorical(df_mat['higher'])\n",
    "df_por['higher'] = pd.Categorical(df_por['higher'])\n",
    "\n",
    "df_mat['internet'] = pd.Categorical(df_mat['internet'])\n",
    "df_por['internet'] = pd.Categorical(df_por['internet'])\n",
    "\n",
    "df_mat['romantic'] = pd.Categorical(df_mat['romantic'])\n",
    "df_por['romantic'] = pd.Categorical(df_por['romantic'])\n",
    "\n",
    "df_mat['famrel'] = pd.to_numeric(df_mat['famrel'], downcast='unsigned')\n",
    "df_por['famrel'] = pd.to_numeric(df_por['famrel'], downcast='unsigned')\n",
    "\n",
    "df_mat['freetime'] = pd.to_numeric(df_mat['freetime'], downcast='unsigned')\n",
    "df_por['freetime'] = pd.to_numeric(df_por['freetime'], downcast='unsigned')\n",
    "\n",
    "df_mat['goout'] = pd.to_numeric(df_mat['goout'], downcast='unsigned')\n",
    "df_por['goout'] = pd.to_numeric(df_por['goout'], downcast='unsigned')\n",
    "\n",
    "df_mat['Dalc'] = pd.to_numeric(df_mat['Dalc'], downcast='unsigned')\n",
    "df_por['Dalc'] = pd.to_numeric(df_por['Dalc'], downcast='unsigned')\n",
    "\n",
    "df_mat['Walc'] = pd.to_numeric(df_mat['Walc'], downcast='unsigned')\n",
    "df_por['Walc'] = pd.to_numeric(df_por['Walc'], downcast='unsigned')\n",
    "\n",
    "df_mat['health'] = pd.to_numeric(df_mat['health'], downcast='unsigned')\n",
    "df_por['health'] = pd.to_numeric(df_por['health'], downcast='unsigned')\n",
    "\n",
    "df_mat['absences'] = pd.to_numeric(df_mat['absences'], downcast='unsigned')\n",
    "df_por['absences'] = pd.to_numeric(df_por['absences'], downcast='unsigned')\n",
    "\n",
    "df_mat['G1'] = pd.to_numeric(df_mat['G1'], downcast='unsigned')\n",
    "df_por['G1'] = pd.to_numeric(df_por['G1'], downcast='unsigned')\n",
    "\n",
    "df_mat['G2'] = pd.to_numeric(df_mat['G2'], downcast='unsigned')\n",
    "df_por['G2'] = pd.to_numeric(df_por['G2'], downcast='unsigned')\n",
    "\n",
    "df_mat['G3'] = pd.to_numeric(df_mat['G3'], downcast='unsigned')\n",
    "df_por['G3'] = pd.to_numeric(df_por['G3'], downcast='unsigned')\n",
    "\n",
    "# adding column to each df to designate the course that the students are in\n",
    "df_mat['course'] = 'mat'\n",
    "df_mat['course'] = pd.Categorical(df_mat['course'])\n",
    "df_por['course'] = 'por'\n",
    "df_por['course'] = pd.Categorical(df_por['course'])\n",
    "\n",
    "# combine data frames\n",
    "df_com = pd.concat([df_mat, df_por], ignore_index=True)\n",
    "df_com['course'] = pd.Categorical(df_com['course'])\n",
    "\n",
    "# convert all categorical attributes in combined dataframe to numeric\n",
    "cat_columns = df_com.select_dtypes(['category']).columns\n",
    "df_com[cat_columns] = df_com[cat_columns].apply(lambda x: x.cat.codes)\n",
    "\n",
    "# standardizing all data (except for grade variables)\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "df_com.loc[:, (df_com.columns != 'G1') & (df_com.columns != 'G2') & (df_com.columns != 'G3')] = min_max_scaler.fit_transform(df_com.loc[:, (df_com.columns != 'G1') & (df_com.columns != 'G2') & (df_com.columns != 'G3')])\n",
    "\n",
    "# downcasting all data\n",
    "df_com = df_com.apply(pd.to_numeric, downcast='float')\n",
    "\n",
    "# dropping first and second period grades in an additional dataset so we can use models on both the dataset that contains these grades and the one that doesn't\n",
    "df_com_alt = df_com.drop(columns=['G1', 'G2'])\n",
    "\n",
    "display(df_com.info())\n",
    "display(df_com_alt.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2bc99ee",
   "metadata": {},
   "source": [
    "### **Modeling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4ea4b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 2.1597762\n",
      "Mean Squared Error: 7.7431164\n",
      "Root Mean Squared Error: 2.7826455\n",
      "R2: 0.17523701152448756\n"
     ]
    }
   ],
   "source": [
    "# separating target variable and all other variables to prepare for modeling\n",
    "target_alt = df_com_alt['G3']\n",
    "target_alt_ohe = pd.get_dummies(target_alt)\n",
    "\n",
    "variables_alt = df_com_alt.drop('G3', axis=1)\n",
    "\n",
    "# splitting training and testing data\n",
    "X_train, X_test, y_train, y_test = train_test_split(variables_alt, target_alt, test_size=0.2, random_state=0)\n",
    "\n",
    "# MULTIPLE LINEAR REGRESSION MODEL (1st & 2nd period grades NOT INCLUDED)\n",
    "# help: https://stackabuse.com/linear-regression-in-python-with-scikit-learn/ and https://www.ritchieng.com/machine-learning-evaluate-linear-regression-model/ and https://scikit-learn.org/stable/modules/model_evaluation.html\n",
    "linear_regression = LinearRegression()\n",
    "linear_regression_clf = linear_regression.fit(X_train, y_train)\n",
    "linear_regression_pred = linear_regression_clf.predict(X_test)\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, linear_regression_pred))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, linear_regression_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, linear_regression_pred)))\n",
    "print('R2:', metrics.r2_score(y_test, linear_regression_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2310a050",
   "metadata": {},
   "source": [
    "There are a few interesting results from using the multiple linear regression model. First, the RMSE is just under 3, while scores range from 0 to 20. This RMSE is about 14% of the total score range, indicating that the model is not particularly accurate but that it can be made to make relatively precise predictions. An R2 score of 0.175, however, indicates that this model is not a good performer as an R2 closer to 1.0 is expected for a well-performing model. Because of this, it is quite clear that the multiple linear regression model is likely not the best model to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e07e6d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>school</th>\n",
       "      <td>-0.908398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex</th>\n",
       "      <td>-0.023556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>0.260008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>address</th>\n",
       "      <td>0.481881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>famsize</th>\n",
       "      <td>0.512326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pstatus</th>\n",
       "      <td>-0.189550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Medu</th>\n",
       "      <td>1.068629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fedu</th>\n",
       "      <td>0.179861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mjob</th>\n",
       "      <td>-0.180635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fjob</th>\n",
       "      <td>0.071070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reason</th>\n",
       "      <td>0.227684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>guardian</th>\n",
       "      <td>-0.353918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>traveltime</th>\n",
       "      <td>0.015607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>studytime</th>\n",
       "      <td>1.103307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>failures</th>\n",
       "      <td>-5.204220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>schoolsup</th>\n",
       "      <td>-1.083919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>famsup</th>\n",
       "      <td>-0.251244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>paid</th>\n",
       "      <td>0.154896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>activities</th>\n",
       "      <td>0.034626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nursery</th>\n",
       "      <td>-0.221390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>higher</th>\n",
       "      <td>1.498129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>internet</th>\n",
       "      <td>0.433928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>romantic</th>\n",
       "      <td>-0.717009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>famrel</th>\n",
       "      <td>0.922149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freetime</th>\n",
       "      <td>0.419067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>goout</th>\n",
       "      <td>-0.820388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dalc</th>\n",
       "      <td>-0.595877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Walc</th>\n",
       "      <td>-0.303160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>health</th>\n",
       "      <td>-0.670060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>absences</th>\n",
       "      <td>2.325304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>course</th>\n",
       "      <td>2.143179</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Coefficient\n",
       "school        -0.908398\n",
       "sex           -0.023556\n",
       "age            0.260008\n",
       "address        0.481881\n",
       "famsize        0.512326\n",
       "Pstatus       -0.189550\n",
       "Medu           1.068629\n",
       "Fedu           0.179861\n",
       "Mjob          -0.180635\n",
       "Fjob           0.071070\n",
       "reason         0.227684\n",
       "guardian      -0.353918\n",
       "traveltime     0.015607\n",
       "studytime      1.103307\n",
       "failures      -5.204220\n",
       "schoolsup     -1.083919\n",
       "famsup        -0.251244\n",
       "paid           0.154896\n",
       "activities     0.034626\n",
       "nursery       -0.221390\n",
       "higher         1.498129\n",
       "internet       0.433928\n",
       "romantic      -0.717009\n",
       "famrel         0.922149\n",
       "freetime       0.419067\n",
       "goout         -0.820388\n",
       "Dalc          -0.595877\n",
       "Walc          -0.303160\n",
       "health        -0.670060\n",
       "absences       2.325304\n",
       "course         2.143179"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# printing the coefficients for each variable and how they affect the target\n",
    "df_co = pd.DataFrame(linear_regression_clf.coef_, variables_alt.columns, columns=['Coefficient'])\n",
    "df_co"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ffea41",
   "metadata": {},
   "source": [
    "While the multiple linear regression model is likely not the best model to use (at least when the first and second period graees are not included), the coefficients given for each variable regarding how they affect the target value is very interesting, as it shows the individual effect each input variable had on the prediction of the target value. Based on this model, it appears that sex, activities, traveltime, and Fjob are all very irrelevant input variables (since their coefficients are very close to 0). Interestingly, it appears that Medu, studytime, higher, famrel, the course taken, and the number of absences all contribute positively to the prediction of the final score. The most surprising variable there is absences, as I would assume that a higher number of abscences would not lead to a prediction of a higher final grade. Finally, it appears that failures and schoolsup have significant negative contributions to the prediction of final score. Increased number of failures in particular appears to be highly correlated with a low final grade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9538db69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.8423875\n",
      "Mean Squared Error: 1.5384248\n",
      "Root Mean Squared Error: 1.2403326\n",
      "R2: 0.8361336894879354\n"
     ]
    }
   ],
   "source": [
    "# separating target variable and all other variables to prepare for modeling\n",
    "target = df_com['G3']\n",
    "target_ohe = pd.get_dummies(target)\n",
    "\n",
    "variables = df_com.drop('G3', axis=1)\n",
    "\n",
    "# splitting training and testing data\n",
    "X_train, X_test, y_train, y_test = train_test_split(variables, target, test_size=0.2, random_state=0)\n",
    "\n",
    "# MULTIPLE LINEAR REGRESSION MODEL (1st & 2nd period grades INCLUDED)\n",
    "# help: https://stackabuse.com/linear-regression-in-python-with-scikit-learn/ and https://www.ritchieng.com/machine-learning-evaluate-linear-regression-model/ and https://scikit-learn.org/stable/modules/model_evaluation.html\n",
    "linear_regression = LinearRegression()\n",
    "linear_regression_clf = linear_regression.fit(X_train, y_train)\n",
    "linear_regression_pred = linear_regression_clf.predict(X_test)\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, linear_regression_pred))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, linear_regression_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, linear_regression_pred)))\n",
    "print('R2:', metrics.r2_score(y_test, linear_regression_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81055c17",
   "metadata": {},
   "source": [
    "There is a very clear improvement to using the multiple linear regression model when the first and second period grades are included. All metrics went down (except R2 of course) with the RMSE only being 1.24 for this model. The R2 also increased significantly from 0.175 to 0.836, indicating that this model is much better at predicting final grade scores when the first and second period grades are included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e81d988",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>school</th>\n",
       "      <td>0.048222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex</th>\n",
       "      <td>-0.032164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>-0.365574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>address</th>\n",
       "      <td>0.116958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>famsize</th>\n",
       "      <td>-0.023849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pstatus</th>\n",
       "      <td>-0.162575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Medu</th>\n",
       "      <td>0.002303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fedu</th>\n",
       "      <td>-0.037170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mjob</th>\n",
       "      <td>0.066570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fjob</th>\n",
       "      <td>-0.558514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reason</th>\n",
       "      <td>-0.098856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>guardian</th>\n",
       "      <td>0.207225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>traveltime</th>\n",
       "      <td>0.439595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>studytime</th>\n",
       "      <td>-0.050748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>failures</th>\n",
       "      <td>-0.972579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>schoolsup</th>\n",
       "      <td>0.213758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>famsup</th>\n",
       "      <td>0.136217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>paid</th>\n",
       "      <td>-0.003948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>activities</th>\n",
       "      <td>-0.095247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nursery</th>\n",
       "      <td>-0.087671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>higher</th>\n",
       "      <td>-0.019479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>internet</th>\n",
       "      <td>0.054696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>romantic</th>\n",
       "      <td>-0.081327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>famrel</th>\n",
       "      <td>0.496247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freetime</th>\n",
       "      <td>0.068553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>goout</th>\n",
       "      <td>-0.211591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dalc</th>\n",
       "      <td>-0.390649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Walc</th>\n",
       "      <td>0.346502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>health</th>\n",
       "      <td>-0.075344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>absences</th>\n",
       "      <td>2.588445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G1</th>\n",
       "      <td>0.168464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G2</th>\n",
       "      <td>0.925952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>course</th>\n",
       "      <td>0.658725</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Coefficient\n",
       "school         0.048222\n",
       "sex           -0.032164\n",
       "age           -0.365574\n",
       "address        0.116958\n",
       "famsize       -0.023849\n",
       "Pstatus       -0.162575\n",
       "Medu           0.002303\n",
       "Fedu          -0.037170\n",
       "Mjob           0.066570\n",
       "Fjob          -0.558514\n",
       "reason        -0.098856\n",
       "guardian       0.207225\n",
       "traveltime     0.439595\n",
       "studytime     -0.050748\n",
       "failures      -0.972579\n",
       "schoolsup      0.213758\n",
       "famsup         0.136217\n",
       "paid          -0.003948\n",
       "activities    -0.095247\n",
       "nursery       -0.087671\n",
       "higher        -0.019479\n",
       "internet       0.054696\n",
       "romantic      -0.081327\n",
       "famrel         0.496247\n",
       "freetime       0.068553\n",
       "goout         -0.211591\n",
       "Dalc          -0.390649\n",
       "Walc           0.346502\n",
       "health        -0.075344\n",
       "absences       2.588445\n",
       "G1             0.168464\n",
       "G2             0.925952\n",
       "course         0.658725"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# printing the coefficients for each variable and how they affect the target\n",
    "df_co = pd.DataFrame(linear_regression_clf.coef_, variables.columns, columns=['Coefficient'])\n",
    "df_co"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90acd02",
   "metadata": {},
   "source": [
    "When the first and second period grades are looked at when using the multiple linear regression model, the variables that appear to have influence over the final grade prediction change. A high number of past failures can still be seen as contributing to a lower predicted final score. Weekday drinking also appears to negatively impact final grade prediction. Second period grades, absences, a good family relationship, and travel time also appear to contribute positively to final scores. This is interesting, as I would not have predicted that high absences or high travel time would positively impact the prediction of the final scores. The course being taken also appears to influence the grade achieved quite a bit. For the most part, no other variables are relevant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f356bbc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt_true</th>\n",
       "      <th>dt_def</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1039</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1040</th>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1041</th>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1042</th>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1043</th>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1044 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      dt_true  dt_def\n",
       "0           6      11\n",
       "1           6       9\n",
       "2          10       6\n",
       "3          15      11\n",
       "4          10      11\n",
       "...       ...     ...\n",
       "1039       10      10\n",
       "1040       16      12\n",
       "1041        9      10\n",
       "1042       10       9\n",
       "1043       11       9\n",
       "\n",
       "[1044 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.152     0.189     0.168        53\n",
      "           1      0.000     0.000     0.000         1\n",
      "           2      0.000     0.000     0.000         0\n",
      "           3      0.000     0.000     0.000         0\n",
      "           4      0.000     0.000     0.000         1\n",
      "           5      0.000     0.000     0.000         8\n",
      "           6      0.026     0.111     0.042        18\n",
      "           7      0.056     0.053     0.054        19\n",
      "           8      0.088     0.239     0.129        67\n",
      "           9      0.067     0.222     0.103        63\n",
      "          10      0.133     0.078     0.099       153\n",
      "          11      0.129     0.119     0.124       151\n",
      "          12      0.078     0.078     0.078       103\n",
      "          13      0.100     0.080     0.089       113\n",
      "          14      0.059     0.011     0.019        90\n",
      "          15      0.211     0.098     0.133        82\n",
      "          16      0.000     0.000     0.000        52\n",
      "          17      0.000     0.000     0.000        35\n",
      "          18      0.000     0.000     0.000        27\n",
      "          19      0.000     0.000     0.000         7\n",
      "          20      0.000     0.000     0.000         1\n",
      "\n",
      "    accuracy                          0.095      1044\n",
      "   macro avg      0.052     0.061     0.049      1044\n",
      "weighted avg      0.097     0.095     0.087      1044\n",
      "\n",
      "Mean Absolute Error: 3.485632183908046\n",
      "Mean Squared Error: 21.487547892720308\n",
      "Root Mean Squared Error: 4.635466308012637\n",
      "R2: -0.4399583876313877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shanestaret/opt/anaconda3/envs/csci349/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/shanestaret/opt/anaconda3/envs/csci349/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/shanestaret/opt/anaconda3/envs/csci349/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/shanestaret/opt/anaconda3/envs/csci349/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/shanestaret/opt/anaconda3/envs/csci349/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/shanestaret/opt/anaconda3/envs/csci349/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# KERAS NN MODEL WITH KFOLD CROSS VALIDATION (1st & 2nd period grades NOT INCLUDED)\n",
    "# help: https://www.pyimagesearch.com/2019/01/21/regression-with-keras/\n",
    "\n",
    "# number of inputs and outputs\n",
    "NUM_INPUTS = 31\n",
    "NUM_OUTPUTS = 19\n",
    "\n",
    "true_list = list(target_alt)\n",
    "\n",
    "# function to properly create Keras model\n",
    "def create_keras_model(optimizer='adam', num_hidden=10, activation='relu'):\n",
    "    inputs = Input(shape=(NUM_INPUTS,))\n",
    "    layer = Dense(num_hidden, activation=activation)(inputs)\n",
    "    outputs = Dense(NUM_OUTPUTS, activation='softmax')(layer)\n",
    "    model = Model(inputs=inputs, outputs=outputs, name=\"keras model\")\n",
    "    model.compile(optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "# generating predictions\n",
    "keras_clf = KerasClassifier(build_fn=create_keras_model, verbose=0, epochs=150, batch_size=4)\n",
    "keras_pred = cross_val_predict(keras_clf, variables_alt, target_alt_ohe, cv=10)\n",
    "\n",
    "df_results = pd.DataFrame(list(zip(true_list, keras_pred)), columns =['dt_true', 'dt_def'])\n",
    "display(df_results)\n",
    "print(classification_report(df_results['dt_true'], df_results['dt_def'], digits=3))\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(true_list, keras_pred))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(true_list, keras_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(true_list, keras_pred)))\n",
    "print('R2:', metrics.r2_score(true_list, keras_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d89ef3c",
   "metadata": {},
   "source": [
    "The output of the Keras NN without the first or second period grades is extremely interesting. Not only does it appear to perform worse than the multiple linear regression model, the R2 value is -0.440...indicating that this model is extremely poor at predicting the final grade based on the 31 input variables. I was expecting the model to not perform very well, however, this is worse than I anticipated. **The one research paper that looked at this dataset concluded that it doesn't appear to be possible to accurately predict final grades without the first and second period grades being known though.** Also, this is mentioned in the \"Conclusion\" section of the research paper. So, since the dataset this model was used on did not include those additional grades, maybe this result is not as unexpected as it first appears.  \n",
    "  \n",
    "Of course another explanation is that this model was set up inappropriately, however I cannot see where I may have gone wrong. The target variable was adjusted to not be numeric and instead be categorical (that's why we are using \"target_alt_ohe\") and the creation of the Keras model follows the structure of previous Keras models that I have created for this class and within other projects. All of the input variables were also standardized. Maybe there is something I'm missing (like one of the activation functions throwing something way off) or perhaps this model performing extremely poorly is not necessarily all that surprising."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "026ae97d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt_true</th>\n",
       "      <th>dt_def</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1039</th>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1040</th>\n",
       "      <td>16</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1041</th>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1042</th>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1043</th>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1044 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      dt_true  dt_def\n",
       "0           6       6\n",
       "1           6       4\n",
       "2          10       6\n",
       "3          15      12\n",
       "4          10       8\n",
       "...       ...     ...\n",
       "1039       10       8\n",
       "1040       16      14\n",
       "1041        9      11\n",
       "1042       10       9\n",
       "1043       11       9\n",
       "\n",
       "[1044 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.474     0.509     0.491        53\n",
      "           1      0.000     0.000     0.000         1\n",
      "           3      0.000     0.000     0.000         0\n",
      "           4      0.000     0.000     0.000         1\n",
      "           5      0.000     0.000     0.000         8\n",
      "           6      0.110     0.556     0.183        18\n",
      "           7      0.000     0.000     0.000        19\n",
      "           8      0.075     0.224     0.113        67\n",
      "           9      0.067     0.190     0.099        63\n",
      "          10      0.075     0.026     0.039       153\n",
      "          11      0.113     0.106     0.110       151\n",
      "          12      0.089     0.068     0.077       103\n",
      "          13      0.062     0.071     0.066       113\n",
      "          14      0.125     0.022     0.038        90\n",
      "          15      0.300     0.110     0.161        82\n",
      "          16      0.094     0.058     0.071        52\n",
      "          17      0.000     0.000     0.000        35\n",
      "          18      0.000     0.000     0.000        27\n",
      "          19      0.000     0.000     0.000         7\n",
      "          20      0.000     0.000     0.000         1\n",
      "\n",
      "    accuracy                          0.108      1044\n",
      "   macro avg      0.079     0.097     0.072      1044\n",
      "weighted avg      0.117     0.108     0.097      1044\n",
      "\n",
      "Mean Absolute Error: 2.2519157088122603\n",
      "Mean Squared Error: 7.953065134099617\n",
      "Root Mean Squared Error: 2.8201179291121172\n",
      "R2: 0.4670363084516823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shanestaret/opt/anaconda3/envs/csci349/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/shanestaret/opt/anaconda3/envs/csci349/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/shanestaret/opt/anaconda3/envs/csci349/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/shanestaret/opt/anaconda3/envs/csci349/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/shanestaret/opt/anaconda3/envs/csci349/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/shanestaret/opt/anaconda3/envs/csci349/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# KERAS NN MODEL WITH KFOLD CROSS VALIDATION (1st & 2nd period grades INCLUDED)\n",
    "# help: https://www.pyimagesearch.com/2019/01/21/regression-with-keras/\n",
    "\n",
    "# number of inputs and outputs\n",
    "NUM_INPUTS = 33\n",
    "NUM_OUTPUTS = 19\n",
    "\n",
    "true_list = list(target)\n",
    "\n",
    "# function to properly create Keras model\n",
    "def create_keras_model(optimizer='adam', num_hidden=10, activation='relu'):\n",
    "    inputs = Input(shape=(NUM_INPUTS,))\n",
    "    layer = Dense(num_hidden, activation=activation)(inputs)\n",
    "    outputs = Dense(NUM_OUTPUTS, activation='softmax')(layer)\n",
    "    model = Model(inputs=inputs, outputs=outputs, name=\"keras model\")\n",
    "    model.compile(optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "# generating predictions\n",
    "keras_clf = KerasClassifier(build_fn=create_keras_model, verbose=0, epochs=150, batch_size=4)\n",
    "keras_pred = cross_val_predict(keras_clf, variables, target_ohe, cv=10)\n",
    "\n",
    "df_results = pd.DataFrame(list(zip(true_list, keras_pred)), columns =['dt_true', 'dt_def'])\n",
    "display(df_results)\n",
    "print(classification_report(df_results['dt_true'], df_results['dt_def'], digits=3))\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(true_list, keras_pred))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(true_list, keras_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(true_list, keras_pred)))\n",
    "print('R2:', metrics.r2_score(true_list, keras_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d1596a",
   "metadata": {},
   "source": [
    "Surprisingly, the Keras NN working on the dataset including the first and second period scores did not perform too well, however an RMSE of 2.82 (~15% of the spread of scores from 0 to 20) is not too bad and an R2 of 0.467 is a great improvement compared to negative R2 score achieved when working on the dataset that excludes the first and second period scores. I am a bit surprised to see that the Keras NN is not achieving as good results as the multiple linear regression model. Perhaps the NN needs more fine-tuning or other activation functions could be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47867802",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
